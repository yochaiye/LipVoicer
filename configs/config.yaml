
melgen:
  _name_: melgen
  in_channels: 80
  out_channels: 80
  diffusion_step_embed_dim_in: 128
  diffusion_step_embed_dim_mid: 512
  diffusion_step_embed_dim_out: 512
  res_channels: 512
  skip_channels: 512
  num_res_layers: 12
  dilation_cycle: 1
  mel_upsample: [2, 2]

diffusion:
  T: 400
  beta_0: 0.0001
  beta_T: 0.02
  beta: null

dataset:
  videos_dir: datasets/LRS3/videos
  mouthrois_dir: datasets/LRS3/mouth_crops
  audios_dir: datasets/LRS3/audios
  sampling_rate: ${audio.sampling_rate}
  videos_window_size: 25
  audio_stft_hop: ${audio.hop_length}

audio:
  sampling_rate: 16000
  filter_length: 640
  hop_length: 160
  win_length: 640
  mel_fmin: 20.0
  mel_fmax: 8000.0

train: # Not used in generate.py
  name: LRS3        # Name of experiment (prefix of experiment name)
  save_dir: null    # where checkpoints will be saved
  ckpt_iter: max    # continue training from a specific iteration
  iters_per_ckpt: 10000
  iters_per_logging: 100
  n_iters: 1000001
  learning_rate: 2e-4
  batch_size_per_gpu: 8

generate:
  name: LRS3
  ckpt_path: exp/LRS3/wnet_h512_d12_T400_betaT0.02/checkpoint/1000000.pkl           
  n_samples: 3          # Number of utterances from test dataset to be generated 
  video_path: null      # generate audio for a given silent video file
  w_video: 2            # w1 in the paper
  w_asr: 1.5            # w2 in the paper
  asr_start: 270        # t_asr
  save_dir: null        # where to save the generated audio
  lipread_text_dir: null # directory with predicted text for generating test samples of benchmark dataset 

distributed:
  dist_backend: nccl
  dist_url: tcp://localhost:54321 #54321
